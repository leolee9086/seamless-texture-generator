import { makeTileable } from '../../../src/lib/HistogramPreservingBlendMakeTileable'
import { scaleImageToMaxResolution } from './imageLoader'
import { processImageWithLUT, processLutData } from '@leolee9086/use-lut'
import { HSLAdjustProcessStep, type HSLAdjustmentLayer } from './hslAdjustStep'
import { adjustExposure, adjustExposureManual } from '../adjustments/exposureAdjustment'  // æ–°å¢å¯¼å…¥
import { applyDehazeAdjustment, DEFAULT_DEHAZE_PARAMS } from '../adjustments/dehaze/dehazeAdjustment'  // æ–°å¢å¯¼å…¥
import { type DehazeParams } from '@/adjustments/dehaze/types'
import { processClarityAdjustment, type ClarityParams } from '../adjustments/clarityAdjustment'  // æ–°å¢å¯¼å…¥
import { applyLuminanceAdjustmentToImageData, type LuminanceAdjustmentParams } from '../adjustments/luminanceAdjustment'  // æ–°å¢å¯¼å…¥

/**
 * ç®¡çº¿æ•°æ®æ¥å£ - ç»Ÿä¸€ä½¿ç”¨ GPUBuffer ä½œä¸ºæ•°æ®è½½ä½“
 */
interface PipelineData {
  buffer: GPUBuffer
  width: number
  height: number
}

/**
 * ç®¡çº¿æ­¥éª¤é€‰é¡¹
 */
interface PipelineOptions {
  maxResolution?: number
  borderSize?: number
  lutFile?: File | null
  lutIntensity?: number
  maskData?: Uint8Array
  hslLayers?: HSLAdjustmentLayer[]
  exposureStrength?: number  // æ–°å¢
  exposureManual?: { exposure: number; contrast: number; gamma: number }  // æ–°å¢
  dehazeParams?: DehazeParams  // æ–°å¢
  clarityParams?: ClarityParams  // æ–°å¢
  luminanceParams?: LuminanceAdjustmentParams  // æ–°å¢
}

/**
 * ç®¡çº¿æ­¥éª¤æ¥å£
 */
interface PipelineStep {
  execute(data: PipelineData, options: PipelineOptions): Promise<PipelineData>
}

/**
 * å·¥å…·å‡½æ•°ï¼šImageData è½¬ GPUBuffer
 */
async function imageDataToGPUBuffer(imageData: ImageData, device: GPUDevice): Promise<GPUBuffer> {
  const buffer = device.createBuffer({
    size: imageData.data.byteLength,
    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST,
    mappedAtCreation: true
  })
  new Uint8Array(buffer.getMappedRange()).set(imageData.data)
  buffer.unmap()
  return buffer
}

/**
 * å·¥å…·å‡½æ•°ï¼šGPUBuffer è½¬ ImageData
 */
async function gpuBufferToImageData(buffer: GPUBuffer, width: number, height: number, device: GPUDevice): Promise<ImageData> {
  const size = width * height * 4
  const stagingBuffer = device.createBuffer({
    size,
    usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ
  })

  const commandEncoder = device.createCommandEncoder()
  commandEncoder.copyBufferToBuffer(buffer, 0, stagingBuffer, 0, size)
  device.queue.submit([commandEncoder.finish()])

  await stagingBuffer.mapAsync(GPUMapMode.READ)
  const copyArrayBuffer = stagingBuffer.getMappedRange()
  const data = new Uint8ClampedArray(copyArrayBuffer.slice(0))
  stagingBuffer.unmap()
  stagingBuffer.destroy()

  return new ImageData(data, width, height)
}

/**
 * è·å–æˆ–åˆå§‹åŒ– WebGPU è®¾å¤‡
 */
let cachedDevice: GPUDevice | null = null
async function getGPUDevice(): Promise<GPUDevice> {
  if (cachedDevice) return cachedDevice

  if (!navigator.gpu) {
    throw new Error('WebGPU ä¸æ”¯æŒ')
  }

  const adapter = await navigator.gpu.requestAdapter()
  if (!adapter) {
    throw new Error('æ— æ³•è·å– GPU é€‚é…å™¨')
  }

  cachedDevice = await adapter.requestDevice()
  return cachedDevice
}

/**
 * æ­¥éª¤ 1: å›¾åƒåŠ è½½å’Œç¼©æ”¾
 */
class ImageLoadStep implements PipelineStep {
  async execute(data: PipelineData, options: PipelineOptions): Promise<PipelineData> {
    // è¿™æ˜¯ç®¡çº¿çš„ç¬¬ä¸€æ­¥ï¼Œdata å‚æ•°å®é™…ä¸Šä¸ä¼šè¢«ä½¿ç”¨
    // æˆ‘ä»¬éœ€è¦ä»å¤–éƒ¨ä¼ å…¥çš„ originalImage åŠ è½½å›¾åƒ
    throw new Error('ImageLoadStep éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä¸èƒ½ç›´æ¥åœ¨ç®¡çº¿ä¸­ä½¿ç”¨')
  }

  /**
   * ä»å›¾åƒ URL åŠ è½½å¹¶ç¼©æ”¾å›¾åƒ
   */
  async loadAndScale(originalImage: string, maxResolution: number): Promise<PipelineData> {
    const device = await getGPUDevice()

    // åˆ›å»ºå›¾åƒå…ƒç´ 
    const img = new Image()
    img.crossOrigin = 'anonymous'

    await new Promise<void>((resolve, reject) => {
      img.onload = () => resolve()
      img.onerror = () => reject(new Error('å›¾åƒåŠ è½½å¤±è´¥'))
      img.src = originalImage
    })

    // ç¼©æ”¾å›¾åƒåˆ°æœ€å¤§åˆ†è¾¨ç‡
    const scaledCanvas = scaleImageToMaxResolution(img, maxResolution)
    const imageData = scaledCanvas.getContext('2d')!.getImageData(0, 0, scaledCanvas.width, scaledCanvas.height)

    // è½¬æ¢ä¸º GPUBuffer
    const buffer = await imageDataToGPUBuffer(imageData, device)

    return {
      buffer,
      width: imageData.width,
      height: imageData.height
    }
  }
}

/**
 * æ­¥éª¤ 2: LUT å¤„ç†
 */
class LUTProcessStep implements PipelineStep {
  async execute(data: PipelineData, options: PipelineOptions): Promise<PipelineData> {
    // å¦‚æœæ²¡æœ‰ LUT æ–‡ä»¶ï¼Œç›´æ¥è¿”å›åŸæ•°æ®
    if (!options.lutFile) {
      return data
    }

    const device = await getGPUDevice()

    try {
      // å°† GPUBuffer è½¬æ¢ä¸º ImageDataï¼ˆå†…éƒ¨å¤„ç†éœ€è¦ï¼‰
      const imageData = await gpuBufferToImageData(data.buffer, data.width, data.height, device)

      // è§£æ LUT æ–‡ä»¶
      const lutResult = await processLutData(options.lutFile, options.lutFile.name)

      // å‡†å¤‡ maskData å¯¹è±¡
      const maskOptions: any = {
        intensity: options.lutIntensity || 1.0
      }

      if (options.maskData) {
        console.log('ğŸ­ åº”ç”¨è’™ç‰ˆ:', imageData)
        maskOptions.maskData = {
          data: options.maskData,
          width: imageData.width,
          height: imageData.height
        }
        maskOptions.maskIntensity = 1.0
        maskOptions.enableMask = true
      } else {
        console.log('âš ï¸ æ— è’™ç‰ˆæ•°æ®')
      }

      // ä½¿ç”¨LUTåº“å¤„ç†å›¾åƒ
      const processResult = await processImageWithLUT(
        { data: new Uint8Array(imageData.data.buffer), width: imageData.width, height: imageData.height },
        lutResult.data,
        maskOptions
      )

      if (processResult.success && processResult.result) {
        // æ›´æ–°å›¾åƒæ•°æ®ä¸ºLUTå¤„ç†åçš„ç»“æœ
        const processedImageData = new ImageData(
          new Uint8ClampedArray(processResult.result),
          imageData.width,
          imageData.height
        )

        // è½¬æ¢å› GPUBuffer
        const processedBuffer = await imageDataToGPUBuffer(processedImageData, device)

        // é”€æ¯æ—§çš„ buffer
        data.buffer.destroy()

        return {
          buffer: processedBuffer,
          width: data.width,
          height: data.height
        }
      }
    } catch (error) {
      console.warn('LUTå¤„ç†å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹å›¾åƒ:', error)
    }

    // LUT å¤„ç†å¤±è´¥æˆ–æœªæˆåŠŸæ—¶è¿”å›åŸæ•°æ®
    return data
  }
}

/**
 * æ­¥éª¤ 3: å¯å¹³é“ºåŒ–å¤„ç†
 */
class TileableProcessStep implements PipelineStep {
  async execute(data: PipelineData, options: PipelineOptions): Promise<PipelineData> {
    // å½“ borderSize ä¸º 0 æ—¶ï¼Œä¸è¿›è¡Œæ— ç¼åŒ–å¤„ç†ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
    if (options.borderSize === 0) {
      return data
    }

    const device = await getGPUDevice()

    // å°† GPUBuffer è½¬æ¢ä¸º ImageDataï¼ˆå†…éƒ¨å¤„ç†éœ€è¦ï¼‰
    const imageData = await gpuBufferToImageData(data.buffer, data.width, data.height, device)

    // å¤„ç†å›¾åƒï¼ˆå¯å¹³é“ºåŒ–ï¼‰
    const processedImageData = await makeTileable(imageData, options.borderSize!, null)

    // è½¬æ¢å› GPUBuffer
    const processedBuffer = await imageDataToGPUBuffer(processedImageData, device)

    // é”€æ¯æ—§çš„ buffer
    data.buffer.destroy()

    return {
      buffer: processedBuffer,
      width: processedImageData.width,
      height: processedImageData.height
    }
  }
}

/**
 * æ­¥éª¤ 4: è¾“å‡ºè½¬æ¢
 */
class OutputConversionStep implements PipelineStep {
  async execute(data: PipelineData, options: PipelineOptions): Promise<PipelineData> {
    // è¿™ä¸ªæ­¥éª¤ä¸ä¿®æ”¹æ•°æ®ï¼Œåªæ˜¯æ ‡è®°ç®¡çº¿ç»“æŸ
    // å®é™…çš„è½¬æ¢å·¥ä½œåœ¨ processImageToTileable å‡½æ•°ä¸­å®Œæˆ
    return data
  }

  /**
   * å°† GPUBuffer è½¬æ¢ä¸º DataURL
   */
  async convertToDataURL(data: PipelineData): Promise<string> {
    const device = await getGPUDevice()

    // å°† GPUBuffer è½¬æ¢ä¸º ImageData
    const imageData = await gpuBufferToImageData(data.buffer, data.width, data.height, device)

    // å°†å¤„ç†åçš„å›¾åƒæ•°æ®è½¬æ¢ä¸ºURL
    const canvas = document.createElement('canvas')
    canvas.width = imageData.width
    canvas.height = imageData.height
    const ctx = canvas.getContext('2d')!
    ctx.putImageData(imageData, 0, 0)

    return canvas.toDataURL()
  }
}

/**
 * å¤„ç†å›¾åƒï¼Œä½¿å…¶å¯å¹³é“º
 * @param originalImage åŸå§‹å›¾åƒURL
 * @param maxResolution æœ€å¤§åˆ†è¾¨ç‡
 * @param borderSize è¾¹ç•Œå¤§å°
 * @param onProcessingStart å¤„ç†å¼€å§‹å›è°ƒ
 * @param onProcessingEnd å¤„ç†ç»“æŸå›è°ƒ
 * @param onError é”™è¯¯å›è°ƒ
 * @returns å¤„ç†åçš„å›¾åƒURL
 */
export async function processImageToTileable(
  originalImage: string,
  maxResolution: number,
  borderSize: number,
  onProcessingStart?: () => void,
  onProcessingEnd?: () => void,
  onError?: (message: string) => void,
  lutFile?: File | null,
  lutIntensity?: number,
  maskData?: Uint8Array,
  hslLayers?: HSLAdjustmentLayer[],
  exposureStrength?: number,  // æ–°å¢å‚æ•°
  exposureManual?: { exposure: number; contrast: number; gamma: number },  // æ–°å¢å‚æ•°
  dehazeParams?: DehazeParams,  // æ–°å¢å‚æ•°
  clarityParams?: ClarityParams,  // æ–°å¢å‚æ•°
  luminanceParams?: LuminanceAdjustmentParams  // æ–°å¢å‚æ•°

): Promise<string> {
  if (!originalImage) {
    throw new Error('åŸå§‹å›¾åƒä¸èƒ½ä¸ºç©º')
  }

  onProcessingStart?.()

  try {
    // æ„å»ºç®¡çº¿é€‰é¡¹
    const options: PipelineOptions = {
      maxResolution,
      borderSize,
      lutFile,
      lutIntensity,
      maskData,
      hslLayers,
      exposureStrength,  // æ–°å¢
      exposureManual,   // æ–°å¢
      dehazeParams,  // æ–°å¢
      clarityParams,  // æ–°å¢
      luminanceParams  // æ–°å¢
    }

    // æ­¥éª¤ 1: åŠ è½½å’Œç¼©æ”¾å›¾åƒ
    const imageLoadStep = new ImageLoadStep()
    let pipelineData = await imageLoadStep.loadAndScale(originalImage, maxResolution)

    // æ­¥éª¤ 2: LUT å¤„ç†
    const lutProcessStep = new LUTProcessStep()
    pipelineData = await lutProcessStep.execute(pipelineData, options)
    // æ­¥éª¤ 2.5: HSLè°ƒæ•´
    if (options.hslLayers && options.hslLayers.length > 0) {
      const device = await getGPUDevice()
      const hslAdjustStep = new HSLAdjustProcessStep()
      pipelineData = await hslAdjustStep.execute(pipelineData, options.hslLayers, device)
    }

    // æ­¥éª¤ 2.6: æ›å…‰è°ƒæ•´ï¼ˆæ–°å¢ï¼‰
    // åªæœ‰å½“æ›å…‰å‚æ•°ä¸ä¸ºé»˜è®¤å€¼(1.0)æ—¶æ‰åº”ç”¨æ›å…‰è°ƒæ•´
    const hasExposureAdjustment = (options.exposureStrength && options.exposureStrength !== 1.0) ||
      (options.exposureManual && (options.exposureManual.exposure !== 1.0 || options.exposureManual.contrast !== 1.0 || options.exposureManual.gamma !== 1.0))

    if (hasExposureAdjustment) {
      const device = await getGPUDevice()
      const imageData = await gpuBufferToImageData(pipelineData.buffer, pipelineData.width, pipelineData.height, device)

      let processedImageData: ImageData
      if (options.exposureStrength && options.exposureStrength !== 1.0) {
        // è‡ªåŠ¨æ›å…‰è°ƒæ•´
        processedImageData = await adjustExposure(imageData, options.exposureStrength)
      } else if (options.exposureManual) {
        // æ‰‹åŠ¨æ›å…‰è°ƒæ•´
        processedImageData = adjustExposureManual(
          imageData,
          options.exposureManual.exposure,
          options.exposureManual.contrast,
          options.exposureManual.gamma
        )
      } else {
        processedImageData = imageData
      }

      // è½¬æ¢å› GPUBuffer
      const processedBuffer = await imageDataToGPUBuffer(processedImageData, device)

      // é”€æ¯æ—§çš„ buffer
      pipelineData.buffer.destroy()

      pipelineData = {
        buffer: processedBuffer,
        width: processedImageData.width,
        height: processedImageData.height
      }
    }

    // æ­¥éª¤ 2.7: å»é›¾è°ƒæ•´ï¼ˆæ–°å¢ï¼‰
    // åªæœ‰å½“å»é›¾å‚æ•°ä¸é»˜è®¤å€¼ä¸åŒæ—¶æ‰åº”ç”¨å»é›¾
    const isDehazeNotDefault = options.dehazeParams && JSON.stringify(options.dehazeParams) !== JSON.stringify(DEFAULT_DEHAZE_PARAMS)

    if (isDehazeNotDefault) {
      const device = await getGPUDevice()
      const imageData = await gpuBufferToImageData(pipelineData.buffer, pipelineData.width, pipelineData.height, device)

      try {
        // åº”ç”¨å»é›¾è°ƒæ•´
        const processedImageData = await applyDehazeAdjustment(imageData, options.dehazeParams!)

        // è½¬æ¢å› GPUBuffer
        const processedBuffer = await imageDataToGPUBuffer(processedImageData, device)

        // é”€æ¯æ—§çš„ buffer
        pipelineData.buffer.destroy()

        pipelineData = {
          buffer: processedBuffer,
          width: processedImageData.width,
          height: processedImageData.height
        }
      } catch (error) {
        console.warn('å»é›¾å¤„ç†å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹å›¾åƒ:', error)
      }
    }

    // æ­¥éª¤ 2.8: æ¸…æ™°åº¦è°ƒæ•´ï¼ˆæ–°å¢ï¼‰
    // åªæœ‰å½“æ¸…æ™°åº¦å‚æ•°ä¸ä¸ºé»˜è®¤å€¼æ—¶æ‰åº”ç”¨æ¸…æ™°åº¦è°ƒæ•´
    // enhancementStrengthå’ŒmacroEnhancementä¸ºå…³é”®å‚æ•°
    const hasClarityAdjustment = options.clarityParams &&
      (options.clarityParams.enhancementStrength !== 1.0 || options.clarityParams.macroEnhancement !== 0.0)

    if (hasClarityAdjustment) {
      const device = await getGPUDevice()
      const imageData = await gpuBufferToImageData(pipelineData.buffer, pipelineData.width, pipelineData.height, device)

      try {
        // åº”ç”¨æ¸…æ™°åº¦è°ƒæ•´
        const processedImageData = await processClarityAdjustment(device, imageData, options.clarityParams!)

        // è½¬æ¢å› GPUBuffer
        const processedBuffer = await imageDataToGPUBuffer(processedImageData, device)

        // é”€æ¯æ—§çš„ buffer
        pipelineData.buffer.destroy()

        pipelineData = {
          buffer: processedBuffer,
          width: processedImageData.width,
          height: processedImageData.height
        }
      } catch (error) {
        console.warn('æ¸…æ™°åº¦å¤„ç†å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹å›¾åƒ:', error)
      }
    }

    // æ­¥éª¤ 2.9: äº®åº¦è°ƒæ•´ï¼ˆæ–°å¢ï¼‰
    // åªæœ‰å½“äº®åº¦å‚æ•°ä¸å…¨ä¸º0æ—¶æ‰åº”ç”¨äº®åº¦è°ƒæ•´
    const hasLuminanceAdjustment = options.luminanceParams && (
      options.luminanceParams.shadows.brightness !== 0 || options.luminanceParams.shadows.contrast !== 0 ||
      options.luminanceParams.shadows.saturation !== 0 || options.luminanceParams.midtones.brightness !== 0 ||
      options.luminanceParams.midtones.contrast !== 0 || options.luminanceParams.midtones.saturation !== 0 ||
      options.luminanceParams.highlights.brightness !== 0 || options.luminanceParams.highlights.contrast !== 0 ||
      options.luminanceParams.highlights.saturation !== 0
    )

    if (hasLuminanceAdjustment) {
      const device = await getGPUDevice()
      const imageData = await gpuBufferToImageData(pipelineData.buffer, pipelineData.width, pipelineData.height, device)

      try {
        // åº”ç”¨äº®åº¦è°ƒæ•´
        const processedImageData = await applyLuminanceAdjustmentToImageData(device, imageData, options.luminanceParams!)

        // è½¬æ¢å› GPUBuffer
        const processedBuffer = await imageDataToGPUBuffer(processedImageData, device)

        // é”€æ¯æ—§çš„ buffer
        pipelineData.buffer.destroy()

        pipelineData = {
          buffer: processedBuffer,
          width: processedImageData.width,
          height: processedImageData.height
        }
      } catch (error) {
        console.warn('äº®åº¦è°ƒæ•´å¤„ç†å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹å›¾åƒ:', error)
      }
    }

    // æ­¥éª¤ 3: å¯å¹³é“ºåŒ–å¤„ç†
    const tileableProcessStep = new TileableProcessStep()
    pipelineData = await tileableProcessStep.execute(pipelineData, options)

    // æ­¥éª¤ 4: è¾“å‡ºè½¬æ¢
    const outputConversionStep = new OutputConversionStep()
    const result = await outputConversionStep.convertToDataURL(pipelineData)

    // æ¸…ç† GPU èµ„æº
    pipelineData.buffer.destroy()

    return result
  } catch (error) {
    const errorMessage = `å¤„ç†å›¾åƒæ—¶å‡ºé”™: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
    onError?.(errorMessage)
    throw error
  } finally {
    onProcessingEnd?.()
  }
}